#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu May 17 22:02:50 2018

@author: xingyichong
"""

from bs4 import BeautifulSoup as BS
import requests
import pprint

CAREER_URL = 'http://jobs.jpmorganchase.com/ListJobs/All/search/state/ny/country/us/city/new-york/sortdesc-postedon/page-'

def career_scraping(page_count = 1):
    response = requests.get(CAREER_URL + str(page_count))
    soup = BS(response.content, 'html.parser')
    
    soup_job_date = soup.find_all('td', {'class':'colpostedon'})
    job_date = [content.text[2:].strip() for content in soup_job_date]
    
    soup_job_name = soup.find_all('td', {'class':'coldisplayjobid'})
    job_name = [content.find('a').get('href').split('/')[4] for content in soup_job_name]
    
    if len(job_name) != len(job_date):
        raise Exception('Job name and date length do not match')
    
    job_dict = dict(zip(job_name, job_date))
    
    return job_dict


def multipage_career_scraping(page_end, page_start = 1):
    multi_dict = {}
    for i in range(page_start, page_end + 1):
        new_dict = career_scraping(i)
        multi_dict = {**multi_dict, **new_dict}
    return multi_dict
    



    
def list_count(x_list):
    count = {}
    for n in x_list:
        if n not in count:
            count[n] = 0
        count[n] += 1
    return count

if __name__ == "__main__":
    results = multipage_career_scraping(3)
    pprint.pprint(results)
    
    date_list = results.values()
    count_results = list_count(date_list)
    pprint.pprint(count_results)
    
